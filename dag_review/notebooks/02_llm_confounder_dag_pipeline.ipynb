{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cb577c-de21-4681-85c7-a7a119d97cd6",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d16dbd87-4389-4a94-9b31-3969e6a30b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d08d580-4767-4d4a-8d69-4d17a49665d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  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\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = input(\"Enter your OpenAI API key: \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "98ada7c3-fd90-4ee4-8986-a453310be345",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae59323-15e3-43b8-8343-4459ebc8e280",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "39117d02-a769-44c4-9f23-c56f91d48dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@\"\n",
    "    f\"{os.getenv('DB_HOST', 'localhost')}:{os.getenv('DB_PORT', '5432')}/{os.getenv('DB_NAME', 'dag_review_db')}\"\n",
    ")\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7536b-8d0f-4b4c-8049-794fe661e8a0",
   "metadata": {},
   "source": [
    "## LLM prompts and schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e7369f4-2386-4755-acf2-13f2d3ddfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\", \"llm\", \"prompts\"))\n",
    "# === PROMPTS TO SUMMARIZE STRUCTURED DATA ===\n",
    "SYSTEM_PROMPT_SUMMARY_TEMPLATE = open(os.path.join(prompt_dir, \"summary_extract_system.txt\")).read()\n",
    "USER_PROMPT_SUMMARY_TEMPLATE = open(os.path.join(prompt_dir, \"summary_extract_user.txt\")).read()\n",
    "\n",
    "summary_schema_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"data\", \"schemas\", \"summary_extract_schema.json\"))\n",
    "with open(summary_schema_path, \"r\") as summary_schema_file:\n",
    "    summary_schema = summary_schema_file.read()\n",
    "    \n",
    "SYSTEM_PROMPT_SUMMARY = SYSTEM_PROMPT_SUMMARY_TEMPLATE.replace(\"{{JSON_SCHEMA}}\", summary_schema)\n",
    "\n",
    "# === PROMPTS TO GENERATE DAG OUTPUT === \n",
    "SYSTEM_PROMPT_DAG_TEMPLATE = open(os.path.join(prompt_dir, \"dag_node_extract_system.txt\")).read()\n",
    "NODE_PROMPT_TEMPLATE = open(os.path.join(prompt_dir, \"dag_node_extract_user.txt\")).read()\n",
    "\n",
    "dag_node_schema_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"data\", \"schemas\", \"dag_node_extract_schema.json\"))\n",
    "with open(dag_node_schema_path, \"r\") as dag_schema_file:\n",
    "    dag_node_schema = dag_schema_file.read()\n",
    "\n",
    "dag_node_schema_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"data\", \"schemas\", \"dag_node_extract_schema.json\"))\n",
    "with open(dag_node_schema_path, \"r\") as dag_schema_file:\n",
    "    dag_node_schema_json = json.load(dag_schema_file)\n",
    "    \n",
    "SYSTEM_PROMPT_DAG = SYSTEM_PROMPT_DAG_TEMPLATE.replace(\"{{JSON_SCHEMA}}\", dag_node_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dbeb9-5340-4fa2-8232-8e2490519c3e",
   "metadata": {},
   "source": [
    "# Core functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee372971-8e91-4a33-be9b-ea973196f5b5",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e3e6447-0c50-454c-85a0-f8cd60ef52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prepares structured object for inclusion in prompt === \n",
    "def format_scientific_variables(scientific_variables):\n",
    "    data = json.loads(scientific_variables)\n",
    "    \n",
    "    result_sections = []\n",
    "    \n",
    "    # Process objectives with * bullets\n",
    "    if data.get('objectives') and len(data['objectives']) > 0:\n",
    "        objectives_section = [\"OBJECTIVES:\"]\n",
    "        for obj in data['objectives']:\n",
    "            objectives_section.append(f\"* {obj['shortLabel']}\")\n",
    "        result_sections.append('\\n'.join(objectives_section))\n",
    "    \n",
    "    # Process eligibility with - bullets  \n",
    "    if data.get('eligibility') and len(data['eligibility']) > 0:\n",
    "        eligibility_section = [\"ELIGIBILITY:\"]\n",
    "        for elig in data['eligibility']:\n",
    "            eligibility_section.append(f\"* {elig['shortLabel']}\")\n",
    "        result_sections.append('\\n'.join(eligibility_section))\n",
    "    \n",
    "    # Process outcomes with - bullets\n",
    "    if data.get('outcomes') and len(data['outcomes']) > 0:\n",
    "        outcomes_section = [\"OUTCOMES:\"]\n",
    "        for outcome in data['outcomes']:\n",
    "            outcomes_section.append(f\"* {outcome['shortLabel']}\")\n",
    "        result_sections.append('\\n'.join(outcomes_section))\n",
    "    \n",
    "    # Join all sections with double newlines\n",
    "    return '\\n\\n'.join(result_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb07d459-96cf-49b2-afc5-6d986a53d906",
   "metadata": {},
   "source": [
    "### DAG formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7a56d9bf-82e5-4f9f-b095-2313b094dc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_dagitty_file(dag_json, study_id, output_dir):\n",
    "    # Create mapping from node ID to label\n",
    "    id_to_label = {node['id']: node['label'] for node in dag_json['nodes']}\n",
    "    \n",
    "    # Build graph using only labels\n",
    "    dag = nx.DiGraph()\n",
    "    node_labels = [node['label'] for node in dag_json['nodes']]\n",
    "    dag.add_nodes_from(node_labels)\n",
    "    \n",
    "    # Add edges using mapped labels\n",
    "    edge_tuples = []\n",
    "    for edge in dag_json['edges']:\n",
    "        from_label = id_to_label[edge['from']]\n",
    "        to_label = id_to_label[edge['to']]\n",
    "        edge_tuples.append((from_label, to_label))\n",
    "    \n",
    "    dag.add_edges_from(edge_tuples)\n",
    "    \n",
    "    # Save to database\n",
    "    with engine.begin() as trans_conn:\n",
    "        # Clear existing DAG for this study\n",
    "        trans_conn.execute(metadata.tables['dag_edges'].delete().where(\n",
    "            metadata.tables['dag_edges'].c.study_id == study_id))\n",
    "        trans_conn.execute(metadata.tables['dag_nodes'].delete().where(\n",
    "            metadata.tables['dag_nodes'].c.study_id == study_id))\n",
    "        \n",
    "        # Insert all nodes first\n",
    "        for node_label in dag.nodes:\n",
    "            trans_conn.execute(metadata.tables['dag_nodes'].insert().values(\n",
    "                study_id=study_id,\n",
    "                node_label=node_label,\n",
    "                node_type='llm',\n",
    "                source='llm'\n",
    "            ))\n",
    "        \n",
    "        # Query back the inserted nodes to get their IDs\n",
    "        node_id_map = {}\n",
    "        node_query = metadata.tables['dag_nodes'].select().where(\n",
    "            metadata.tables['dag_nodes'].c.study_id == study_id\n",
    "        )\n",
    "        result = trans_conn.execute(node_query)\n",
    "        for row in result:\n",
    "            node_id_map[row.node_label] = row.id\n",
    "        \n",
    "        # Insert edges using the database node IDs\n",
    "        for from_label, to_label in dag.edges:\n",
    "            from_node_id = node_id_map.get(from_label)\n",
    "            to_node_id = node_id_map.get(to_label)\n",
    "            \n",
    "            if from_node_id is not None and to_node_id is not None:\n",
    "                trans_conn.execute(metadata.tables['dag_edges'].insert().values(\n",
    "                    study_id=study_id,\n",
    "                    from_node_id=from_node_id,\n",
    "                    to_node_id=to_node_id,\n",
    "                    relation_type='llm',\n",
    "                    confidence=1.0\n",
    "                ))\n",
    "            else:\n",
    "                print(f\"Warning: Could not find node IDs for edge {from_label} -> {to_label}\")\n",
    "    \n",
    "    # Export DAGitty format\n",
    "    dagitty = \"dag {\\n\"\n",
    "    \n",
    "    # Add nodes (only labels, no duplicates)\n",
    "    for node_label in dag.nodes:\n",
    "        safe_node = node_label.replace('\"', \"'\")\n",
    "        dagitty += f'\"{safe_node}\"\\n'\n",
    "    \n",
    "    # Add edges\n",
    "    for from_label, to_label in dag.edges:\n",
    "        safe_from = from_label.replace('\"', \"'\")\n",
    "        safe_to = to_label.replace('\"', \"'\")\n",
    "        dagitty += f'\"{safe_from}\" -> \"{safe_to}\"\\n'\n",
    "    \n",
    "    dagitty += \"}\"\n",
    "    \n",
    "    # Write to file\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dagitty_txt_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.txt\")\n",
    "    with open(dagitty_txt_path, \"w\") as f:\n",
    "        f.write(dagitty + \"\\n\")\n",
    "\n",
    "    json_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.json\")\n",
    "    print(f\"json_path {json_path}\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(dag_json, f, indent=2)\n",
    "    \n",
    "    return dagitty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c8afff14-2de8-4c2e-a616-432cddd4d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create R Markdown file to render DAG\n",
    "def generate_rmd_dag(output_dir, study_id):\n",
    "    rmd_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.Rmd\")\n",
    "    json_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.json\")\n",
    "    txt_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.txt\")\n",
    "    rmd_content = f\"\"\"---\n",
    "title: \"DAGitty DAG for Study {study_id}\"\n",
    "output: html_document\n",
    "---\n",
    "```{{r setup, include=FALSE}}\n",
    "library(dagitty)\n",
    "library(ggdag)\n",
    "library(ggplot2)\n",
    "library(jsonlite)\n",
    "```\n",
    "\n",
    "```{{r load-and-plot-dag}}\n",
    "# Read the structure JSON to get node labels\n",
    "structure_data <- fromJSON('{json_path}') \n",
    "\n",
    "# Create a mapping from ID to label\n",
    "node_mapping <- setNames(structure_data$nodes$label, structure_data$nodes$id)\n",
    "\n",
    "dag_text <- readLines(\"dagitty_study_2.txt\")\n",
    "dag <- dagitty(paste(dag_text, collapse = \"\\n\"))\n",
    "\n",
    "tidy_dag <- tidy_dagitty(dag)\n",
    "\n",
    "# Plot using direct labels\n",
    "ggplot(tidy_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n",
    "  geom_dag_edges() +\n",
    "  geom_dag_node(color = \"lightblue\", size = 8) +\n",
    "\n",
    "  # Use geom_label instead of geom_dag_text for styled labels\n",
    "  geom_label(\n",
    "    aes(label = name, y = y - 0.2),  \n",
    "    label.size = 0.2,                \n",
    "    label.r = unit(0.1, \"lines\"),    \n",
    "    color = \"black\",                 \n",
    "    fill = \"white\",                  \n",
    "    label.padding = unit(0.15, \"lines\"),\n",
    "    label.color = \"pink\",          \n",
    "    size = 3                         \n",
    "  ) +\n",
    "\n",
    "  theme_dag() +\n",
    "  theme(legend.position = \"none\")\n",
    "```\"\"\"\n",
    "    with open(rmd_path, \"w\") as rmd_file:\n",
    "        rmd_file.write(rmd_content)\n",
    "\n",
    "    import subprocess\n",
    "    subprocess.run([\"Rscript\", \"-e\", f\"rmarkdown::render('{rmd_path}')\"])\n",
    "    html_path = os.path.join(output_dir, f\"dagitty_study_{study_id}.html\")\n",
    "    if os.path.exists(html_path):\n",
    "        import webbrowser\n",
    "        webbrowser.open(f\"file://{os.path.abspath(html_path)}\")\n",
    "\n",
    "    return rmd_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0556e0d-93e4-4330-af2a-11031dec4b33",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "04e5ada4-e95c-46d5-9c4b-8aa13c25c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_variables_llm(study_id):\n",
    "    with engine.connect() as conn:\n",
    "        objectives = [row._mapping['content'] for row in conn.execute(\n",
    "            metadata.tables['objectives'].select().where(\n",
    "                metadata.tables['objectives'].c.study_id == study_id))]\n",
    "\n",
    "        eligibility = [row._mapping['criteria'] for row in conn.execute(\n",
    "            metadata.tables['eligibility_criteria'].select().where(\n",
    "                metadata.tables['eligibility_criteria'].c.study_id == study_id))]\n",
    "\n",
    "        outcomes = []\n",
    "        for row in conn.execute(metadata.tables['outcomes'].select().where(\n",
    "            metadata.tables['outcomes'].c.study_id == study_id)):\n",
    "            data = row._mapping.get('data')\n",
    "            if isinstance(data, list) and data and isinstance(data[0], dict) and 'value' in data[0]:\n",
    "                outcomes.append(data[0]['value'])\n",
    "            else:\n",
    "                outcomes.append(str(data))\n",
    "\n",
    "        # Step 1: Summarize terms\n",
    "        object_summarization = f\"\"\"\n",
    "OBJECTIVES:\n",
    "{json.dumps(objectives, indent=2)}\n",
    "\n",
    "ELIGIBILITY CRITERIA:\n",
    "{json.dumps(eligibility, indent=2)}\n",
    "\n",
    "OUTCOMES:\n",
    "{json.dumps(outcomes, indent=2)}\n",
    "\"\"\"\n",
    "        \n",
    "        USER_PROMPT_SUMMARY = USER_PROMPT_SUMMARY_TEMPLATE.replace(\"{{OBJECT_SUMMARY}}\", object_summarization)\n",
    "        summary_response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT_SUMMARY},\n",
    "                {\"role\": \"user\", \"content\": USER_PROMPT_SUMMARY}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        scientific_variables = summary_response.choices[0].message.content\n",
    "\n",
    "        summarized_variables = format_scientific_variables(scientific_variables)\n",
    "\n",
    "        return summarized_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "75206293-6c9c-44e2-91af-96b874ec030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_dag_llm(variable_summary, study_id, output_dir):\n",
    "        DAG_PROMPT = NODE_PROMPT_TEMPLATE.replace(\"{{SCIENTIFIC_VARIABLES}}\", variable_summary)\n",
    "\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"RWE DAG Generator\",\n",
    "            instructions=SYSTEM_PROMPT_DAG,\n",
    "            model=\"gpt-4\",\n",
    "            tools=[{\"type\": \"function\", \"function\": {\"name\": \"generate_dag\", \"parameters\": dag_node_schema_json}}]\n",
    "        )\n",
    "        \n",
    "        thread = client.beta.threads.create()\n",
    "        \n",
    "        client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=DAG_PROMPT\n",
    "        )\n",
    "        \n",
    "        run = client.beta.threads.runs.create_and_poll(thread_id=thread.id, assistant_id=assistant.id)\n",
    "        \n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        response_content = messages.data[0].content[0].text.value\n",
    "        \n",
    "        try:\n",
    "            structured_dag_proposal = json.loads(response_content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Invalid JSON: {e}\\n\\nContent:\\n{response_content}\")\n",
    "        \n",
    "        try:\n",
    "            jsonschema.validate(instance=structured_dag_proposal, schema=dag_node_schema_json)\n",
    "        except jsonschema.ValidationError as e:\n",
    "            raise ValueError(f\"Response did not match schema: {e.message}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        structured_dag_path = os.path.join(output_dir, f\"structured_dag_study_{study_id}.json\")\n",
    "        with open(structured_dag_path, \"w\") as f:\n",
    "            json.dump(structured_dag_proposal, f, indent=2)\n",
    "        \n",
    "        return structured_dag_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe33cc-6f0d-48e5-98ab-7d42aa35a41a",
   "metadata": {},
   "source": [
    "# Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0eca75af-6ba1-4ffd-843a-cefd06040e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ... \n",
      " ... running standardize_variables_llm\n",
      " ... \n",
      "\n",
      "  1 | VARIABLE SUMMARY\n",
      "\n",
      " OBJECTIVES:\n",
      "* SBHF Prevalence in T2DM\n",
      "\n",
      "ELIGIBILITY:\n",
      "* T2DM Patients without CVD\n",
      "\n",
      "OUTCOMES:\n",
      "* Echocardiographic Parameters\n",
      "\n",
      " ... \n",
      " ... running propose_dag_llm\n",
      " ... \n",
      "\n",
      "  2 | STRUCTURED DAG PROPOSAL \n",
      "\n",
      " {'nodes': [{'id': '1', 'label': 'T2DM'}, {'id': '2', 'label': 'SBHF Prevalence in T2DM'}, {'id': '3', 'label': 'Echocardiographic Parameters'}, {'id': '4', 'label': 'Age'}, {'id': '5', 'label': 'Sex'}, {'id': '6', 'label': 'BMI'}, {'id': '7', 'label': 'Hypertension'}, {'id': '8', 'label': 'Smoking Status'}, {'id': '9', 'label': 'Cholesterol Levels'}], 'edges': [{'from': '1', 'to': '2'}, {'from': '4', 'to': '1'}, {'from': '5', 'to': '1'}, {'from': '6', 'to': '1'}, {'from': '7', 'to': '1'}, {'from': '8', 'to': '1'}, {'from': '9', 'to': '1'}, {'from': '4', 'to': '3'}, {'from': '5', 'to': '3'}, {'from': '6', 'to': '3'}, {'from': '7', 'to': '3'}, {'from': '2', 'to': '3'}]}\n",
      "\n",
      " ... \n",
      " ... running generate_dagitty_file\n",
      " ... \n",
      " ... running generate_rmd_dag\n",
      "\n",
      " ... \n",
      "\n",
      "  3 | DAG FILE DIRECTORY\n",
      "\n",
      " /Users/aimeeharrison/causal-commons/dag_review/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "processing file: dagitty_study_2.Rmd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4                    \n",
      "2/4 [setup]            \n",
      "3/4                    \n",
      "4/4 [load-and-plot-dag]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in `open.connection()`:\n",
      "! cannot open the connection\n",
      "Backtrace:\n",
      "    ▆\n",
      " 1. └─jsonlite::fromJSON(\"/Users/aimeeharrison/causal-commons/dag_review/output\")\n",
      " 2.   └─jsonlite:::parse_and_simplify(...)\n",
      " 3.     └─jsonlite:::parseJSON(txt, bigint_as_char)\n",
      " 4.       └─jsonlite:::parse_con(txt, bigint_as_char)\n",
      " 5.         ├─base::open(con, \"rb\")\n",
      " 6.         └─base::open.connection(con, \"rb\")\n",
      "\n",
      "Quitting from dagitty_study_2.Rmd:12-37 [load-and-plot-dag]\n",
      "Execution halted\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[197], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ... \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ... running generate_rmd_dag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ... \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  3 | DAG FILE DIRECTORY\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdagitty_file_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgenerate_rmd_dag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdagitty_file_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[192], line 45\u001b[0m, in \u001b[0;36mgenerate_rmd_dag\u001b[0;34m(dagitty_txt_path, study_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m     44\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRscript\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-e\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmarkdown::render(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmd_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 45\u001b[0m html_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43moutput_dir\u001b[49m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdagitty_study_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(html_path):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwebbrowser\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "study_id = 2\n",
    "output_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"output\"))\n",
    "print(f\"\\n ... \\n ... running standardize_variables_llm\")\n",
    "variable_summary = standardize_variables_llm(study_id)\n",
    "print(f\" ... \\n\\n  1 | VARIABLE SUMMARY\\n\\n {variable_summary}\")\n",
    "print(f\"\\n ... \\n ... running propose_dag_llm\")\n",
    "structured_dag_proposal = propose_dag_llm(variable_summary, study_id, output_dir) \n",
    "print(f\" ... \\n\\n  2 | STRUCTURED DAG PROPOSAL \\n\\n {structured_dag_proposal}\")\n",
    "print(f\"\\n ... \\n ... running generate_dagitty_file\")\n",
    "dagitty = generate_dagitty_file(structured_dag_proposal, study_id, output_dir)\n",
    "print(f\" ... \\n ... running generate_rmd_dag\")\n",
    "print(f\"\\n ... \\n\\n  3 | DAGITTY \\n\\n {dagitty}\")\n",
    "generate_rmd_dag(dagitty_file_directory, study_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a10c1d0b-a96b-46a0-b6c3-924049c9ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ... \n",
      " ... running generate_dagitty_file\n",
      "json_path /Users/aimeeharrison/causal-commons/dag_review/output/dagitty_study_2.json\n",
      "\n",
      " ... \n",
      "\n",
      "  3 | DAGITTY \n",
      "\n",
      " dag {\n",
      "\"T2DM\"\n",
      "\"SBHF Prevalence in T2DM\"\n",
      "\"Echocardiographic Parameters\"\n",
      "\"Age\"\n",
      "\"Sex\"\n",
      "\"BMI\"\n",
      "\"Hypertension\"\n",
      "\"Smoking Status\"\n",
      "\"Cholesterol Levels\"\n",
      "\"T2DM\" -> \"SBHF Prevalence in T2DM\"\n",
      "\"SBHF Prevalence in T2DM\" -> \"Echocardiographic Parameters\"\n",
      "\"Age\" -> \"T2DM\"\n",
      "\"Age\" -> \"Echocardiographic Parameters\"\n",
      "\"Sex\" -> \"T2DM\"\n",
      "\"Sex\" -> \"Echocardiographic Parameters\"\n",
      "\"BMI\" -> \"T2DM\"\n",
      "\"BMI\" -> \"Echocardiographic Parameters\"\n",
      "\"Hypertension\" -> \"T2DM\"\n",
      "\"Hypertension\" -> \"Echocardiographic Parameters\"\n",
      "\"Smoking Status\" -> \"T2DM\"\n",
      "\"Cholesterol Levels\" -> \"T2DM\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"output\"))\n",
    "print(f\"\\n ... \\n ... running generate_dagitty_file\")\n",
    "dagitty = generate_dagitty_file(structured_dag_proposal, study_id, output_dir)\n",
    "print(f\"\\n ... \\n\\n  3 | DAGITTY \\n\\n {dagitty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "05bd1003-83e6-403b-8ee2-027aa567183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... \n",
      " ... running generate_rmd_dag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "processing file: dagitty_study_2.Rmd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4                    \n",
      "2/4 [setup]            \n",
      "3/4                    \n",
      "4/4 [load-and-plot-dag]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output file: dagitty_study_2.knit.md\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin/pandoc +RTS -K512m -RTS dagitty_study_2.knit.md --to html4 --from markdown+autolink_bare_uris+tex_math_single_backslash --output dagitty_study_2.html --lua-filter /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rmarkdown/rmarkdown/lua/pagebreak.lua --lua-filter /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rmarkdown/rmarkdown/lua/latex-div.lua --lua-filter /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rmarkdown/rmarkdown/lua/table-classes.lua --embed-resources --standalone --variable bs3=TRUE --section-divs --template /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rmarkdown/rmd/h/default.html --no-highlight --variable highlightjs=1 --variable theme=bootstrap --mathjax --variable 'mathjax-url=https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' --include-in-header /var/folders/g5/fk0fxc8n0b56nqrtwj8ywdlm0000gn/T//RtmpmZPhgc/rmarkdown-str172676ecf2dff.html \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Output created: dagitty_study_2.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/aimeeharrison/causal-commons/dag_review/output/dagitty_study_2.Rmd'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(f\" ... \\n ... running generate_rmd_dag\")\n",
    "generate_rmd_dag(output_dir, study_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c214093-6580-485a-9433-3ac8a574e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonlite::fromJSON(\"/Users/aimeeharrison/causal-commons/dag_review/output/dagitty_study_2.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
